
export declare const AudioState: {
    IDLE: string;
    ARMED: string;
    RECORDING: string;
};

export declare class AudioEngine {
    context: AudioContext | null;
    sourceNode: MediaStreamAudioSourceNode | null;
    analyserNode: AnalyserNode | null;
    inputSplitter: ChannelSplitterNode | null;
    inputAnalyserL: AnalyserNode | null;
    inputAnalyserR: AnalyserNode | null;
    playbackSplitter: ChannelSplitterNode | null;
    playbackAnalyserL: AnalyserNode | null;
    playbackAnalyserR: AnalyserNode | null;
    gainNode: GainNode | null;
    mediaStreamDestination: MediaStreamAudioDestinationNode | null;
    mediaRecorder: MediaRecorder | null;
    state: string;
    activeSource: AudioBufferSourceNode | null;
    playbackStartTime: number;
    currentPlaybackRate: number;
    isLooping: boolean;
    recordedChunks: BlobPart[];
    recordingBuffer: { min: number; max: number }[];
    onRecordingDataAvailable: ((blob: Blob) => void) | null;
    onRecordingStopped: ((blob: Blob, audioBuffer: AudioBuffer | null) => void) | null;
    onPlaybackEnded: (() => void) | null;
    onThresholdExceeded: (() => void) | null;
    outputVolume: number;
    threshold: number;
    isMonitoringThreshold: boolean;

    constructor();
    initContext(): void;
    connectStream(streamId: string): Promise<boolean>;
    connectDisplayMedia(): Promise<boolean>;
    startRecording(): void;
    stopRecording(): void;
    play(buffer: AudioBuffer, trimStart: number, trimEnd: number, loop: boolean, playbackRate?: number): void;
    stop(fadeOut?: boolean): void;
    playSnippet(buffer: AudioBuffer, startPct: number, durationSec?: number): void;
    getAnalyserData(timeData: Uint8Array): void;
    getStereoLevels(): { left: number; right: number };
    setVolume(val: number): void;
    processLiveAudio(timeData: Uint8Array): void;
    checkThreshold(): void;
    startThresholdMonitoring(): void;
    stopThresholdMonitoring(): void;
    crop(sample: any): Promise<AudioBuffer | null>;
    normalize(buffer: AudioBuffer): Promise<AudioBuffer>;
    reverse(buffer: AudioBuffer): Promise<AudioBuffer>;
    resampleBuffer(buffer: AudioBuffer, targetSampleRate: number): Promise<AudioBuffer>;
    downsample(buffer: AudioBuffer, targetRate: number): Promise<AudioBuffer>;
    bitcrush(buffer: AudioBuffer, bitDepth: number): AudioBuffer;
    detectTransients(buffer: AudioBuffer, thresholdPercent?: number, options?: {
        detectedBPM?: number | null;
        bpmConfidence?: number;
        bpmWeight?: number;
        lookbackMs?: number;
        beatTolerance?: number;
    }): Promise<number[]>;
    detectTransientsFallback(buffer: AudioBuffer, thresholdPercent?: number): number[];
    createChops(buffer: AudioBuffer, chopPoints: number[]): Array<{ buffer: AudioBuffer; startFrame: number; endFrame: number; startTime: number; endTime: number }>;
    equalDivide(buffer: AudioBuffer, sliceCount: number): Array<{ buffer: AudioBuffer; startFrame: number; endFrame: number; startTime: number; endTime: number }>;
    applyEffectsAndResample(buffer: AudioBuffer, targetSampleRate?: number | null): Promise<AudioBuffer>;
    setDelay(time: number, feedback: number, mix: number): void;
    setReverb(roomSize: number, damping: number, mix: number): void;
    setEQ(params: {
        enabled?: boolean;
        lowGain?: number;
        lowFreq?: number;
        midGain?: number;
        midFreq?: number;
        midQ?: number;
        highGain?: number;
        highFreq?: number;
    }): void;
    getSampleRate(): number;
    bufferToBlob(buffer: AudioBuffer): Blob;
    detectBPM(buffer: AudioBuffer): Promise<{ bpm: number; threshold: number } | null>;
    detectKey(buffer: AudioBuffer): Promise<{ key: string; mode: 'major' | 'minor'; confidence: number; alternativeKeys?: Array<{ key: string; mode: 'major' | 'minor'; confidence: number }> } | null>;
    analyzeAudio(buffer: AudioBuffer): Promise<{ key: { key: string; mode: string; confidence: number } | null; bpm: { bpm: number; threshold: number } | null }>;
    timeStretch(buffer: AudioBuffer, stretchRatio: number, onProgress?: ((progress: number) => void) | null): Promise<AudioBuffer>;
    timeStretchWithPitch(buffer: AudioBuffer, stretchRatio: number, pitchShiftSemitones: number): Promise<AudioBuffer>;
    separateStems(buffer: AudioBuffer, options?: { modelType?: '2stems' | '4stems' | '5stems'; quality?: 'low' | 'medium' | 'high'; useServer?: boolean }): Promise<{ vocals?: AudioBuffer; drums?: AudioBuffer; bass?: AudioBuffer; other?: AudioBuffer; accompaniment?: AudioBuffer } | null>;
    separateStemsServer(buffer: AudioBuffer, apiEndpoint: string, options?: { modelType?: '2stems' | '4stems' | '5stems'; quality?: 'low' | 'medium' | 'high' }): Promise<{ vocals?: AudioBuffer; drums?: AudioBuffer; bass?: AudioBuffer; other?: AudioBuffer; accompaniment?: AudioBuffer } | null>;
}
